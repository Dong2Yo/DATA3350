{
 "cells": [
  {
   "attachments": {
    "8c7b1c29-6929-4071-86e5-9a83bdafc2bc.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Team Data Science Process Workshop\n",
    "\n",
    "![image.png](attachment:8c7b1c29-6929-4071-86e5-9a83bdafc2bc.png)\n",
    "#### Microsoft Cloud and AI Team\n",
    "\n",
    "The Team Data Science Process (TDSP) is an agile, iterative data science methodology to deliver predictive analytics solutions and intelligent applications efficiently. TDSP helps improve team collaboration and learning. It contains a distillation of the best practices and structures from Microsoft and others in the industry that facilitate the successful implementation of data science initiatives. The goal is to help companies fully realize the benefits of their analytics program."
   ]
  },
  {
   "attachments": {
    "9543f4b6-78a1-4e92-9973-e07a70f1f89c.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABcAAAAYCAYAAAARfGZ1AAACcklEQVRIDY3V61IqMRAE4H3/8oIXRFARH9GiQEUh1jfHTu3xx5apiknm0tPTyeLQWmun08lS4/Pzs93d3bXFYtHm83m7v79vt7e3Ndmcl8tltyVW8vF4/EFp7evrqw3ADodDB7Z5eHioAsCvrq4KLMBnZ2dVgE+cVbExwRQaUkqRjMvLy54EQIGAPz4+Fvj19XUTp6vNZtM+Pj6SXqwV6+Dv7+9l7BGttZubm3Z+ft6en597wn6/bwpgu16vK/z19bXW3+wLXEIG3QTRDCuaWo0k68RkF5eu+eVnDpwZ0T5r9LQauTASAWYfy5HiiS3mklIkwAK8DBP7sBFHFsAmabbbbc9PAfFdc2AS40xyWPIb/Gzu47ePP92JG8LoX2rrz1Jikr0YI9rmeeoIidVqVb4AJ65rPr5UemImMQUwSVdeymw265KJNYAnxrmYl+fnjwCAgOltxQSgDi4uLspGa3FsyHj3Ye7e7PuFwt7tdgWiTcFh7Zy9gvmwFCZNSMD4jznD+DlhqM2np6dK5HfGDiiwcSHAJGIzA67b/lq0kY9DgfwESLb3iQNRxFNUxJ7PF6wL3Y6f8vD29oZcDQEvLy8VJNnABmOJ5EFAJ+wKI8LHZi8m2hdz7zv6CZSEFZs9m2LOAeCPXCHgLC4f5BCN0qYk07CyT03AITYmJb9+zyXnw3CRAcZyCphPV+4g+YqZ9RT9cVkMaZMNmzCaKoCAi857T7e6GBjdeFjkhyk6TwHzAQMUIvYKsg/RSaCbNvIP4i8FJsHJEdbRLfLEN8V+Uhb65mt0MfRz1uZfwCcvtHRorcDyTqNldJxijkDiSAzD2fgGnyvfpaYXpToAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The TDSP comprises of the following key components:\n",
    "\n",
    " - A data science lifecycle definition\n",
    " - A standardized project structure\n",
    " - Infrastructure and resources for data science projects\n",
    " - Tools and utilities for project execution\n",
    "    \n",
    "![image.png](attachment:9543f4b6-78a1-4e92-9973-e07a70f1f89c.png)\n",
    "**Note:** \n",
    "    \n",
    "*You can follow a complete example of this process using Azure Machine Learning* \n",
    "</br>\n",
    "\n",
    "- [\"Biomedical entity recognition using Team Data Science Process (TDSP) Template\"](https://docs.microsoft.com/en-us/azure/machine-learning/preview/scenario-tdsp-biomedical-recognition?toc=%2Fen-us%2Fazure%2Fmachine-learning%2Fteam-data-science-process%2Ftoc.json&bc=%2Fen-us%2Fazure%2Fbread%2Ftoc.json)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*This workshop guides you through a series of exercises you can use to learn to implement the TDSP in your Data Science project, using only Python in a Notebook. You can change the **Setup** and **Lab** cells in this Notebook to use another language, another platform, and with more or fewer prompts based on your audience's needs.*\n",
    "\n",
    "For the labs below, Look for the sections marked: \n",
    "\n",
    "`# <TODO: REPLACE THIS COMMENT WITH PYTHON CODE>`\n",
    "\n",
    "There may be one line needed, but most often more than that - read the entire code snippet to see what you need to do. \n",
    "\n",
    "[Try to figure out the labs yourself, then search the web, then ask your neighbor - and if you're really stuck, check the answer-sheet](.\\AnswerKey.txt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#LAB0 Setup - Get everything up to date, and add any pips you want here\n",
    "\n",
    "# FYI - You can list all libraries in this environment if you like: \n",
    "#import pip\n",
    "#installed_packages = pip.get_installed_distributions()\n",
    "#installed_packages_list = sorted([\"%s==%s\" % (i.key, i.version)\n",
    "#  for i in installed_packages])\n",
    "#print(installed_packages_list)\n",
    "\n",
    "# Import Libraries for the Customer Churn Prediction Labs - Change for other uses\n",
    "# For serializing output/input\n",
    "import pickle\n",
    "\n",
    "# Libraries for training and scoring\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Data and Numeric Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Working with files\n",
    "import csv\n",
    "\n",
    "#/LAB0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img style=\"float: center;\" height=\"800\" width=\"800\" src=\"https://azure.github.io/LearnAI-Bootcamp/lab03.1-tdsp_and_aml/resources/docs/images/tdsp.png\">\n",
    "\n",
    "[We will use the documentation at this location for the class](https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lab 0.0 - Clone the TDSP Structure (Note - Already done  for this lab)\n",
    "\n",
    "*Note: If you have cloned this Notebook, you will already have this structure. Use this\n",
    "Information as a guide for your production environments. Recommend you place the structures\n",
    "at the root of your project, rather than under the **Azure-TDSP-ProjectTemplate** folder.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Instructions (If you're using a local Jupyter Notebook Server):\n",
    "1. Install and configure git if you don't have it.\n",
    "2. Change directories to the root of where you would like to lay out your template (your Jupyter Notbook root project folder, Visual Studio folder, etc.)\n",
    "3. Run the following command from that directory: \n",
    "\n",
    "`git clone https://github.com/Azure/Azure-TDSP-ProjectTemplate.git`\n",
    "\n",
    "#### Lab verification\n",
    " ■ Check that the file structure matches what you see [in this reference](https://github.com/Azure/Azure-TDSP-ProjectTemplate)\n",
    " \n",
    "<p style=\"border-bottom: 1px solid lightgrey;\"></p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Lab 0.1 - Review and Download Project Planning Documents\n",
    "\n",
    "Instructions:\n",
    "1. [Open and review this reference](https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/team-data-science-process-project-templates)\n",
    "2. Download either the Microsoft Project template or Microsoft Excel file noted in that location.  \n",
    "\n",
    "#### Lab verification\n",
    "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"./assets/checkbox.png\">Open the Microsoft Project Template or the Microsoft Excel file. For the Excel file you can use Microsoft Office 365, a compatible spreadsheet viewer or the [free Microsoft Excel viewer](https://www.microsoft.com/en-us/download/details.aspx?id=10)</p>\n",
    "\n",
    "<p style=\"border-bottom: 1px solid lightgrey;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"./assets/check.png\">Phase One - Business Understanding</h2>\n",
    "\n",
    "In the Business Understanding Phase the team determines the prediction or categorical work your organization wants to create. You'll also set up your project planning documents, locate your initial data source locations, and set up the environment you will use to create and operationalize your models. This phase involves a great deal of coordination among the team and the broader organization.\n",
    "\n",
    "Read the [Documentation Reference here](https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/lifecycle-business-understanding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Goals for Business Understanding**\n",
    " - Specify the key variables that are to serve as the model targets and whose related metrics are used determine the success of the project.\n",
    " - Identify the relevant data sources that the business has access to or needs to obtain.\n",
    "\n",
    "**How to do it**\n",
    "(There are two main tasks addressed in this stage)\n",
    " - Define objectives: Work with your customer and other stakeholders to understand and identify the business problems. Formulate questions that define the business goals that the data science techniques can target.\n",
    " - Identify data sources: Find the relevant data that helps you answer the questions that define the objectives of the project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><img style=\"float: right; margin: 0px 15px 15px 0px;\" src=\"./assets/aml-logo.png\"><b>Using Azure Machine Learnin for Business Understanding:</b></p>\n",
    "\n",
    "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"./assets/checkbox.png\">[Identify scenarios and plan for advanced analytics data processing](https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/plan-your-environment)</p>\n",
    "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"./assets/checkbox.png\">[Fill out the project Charter Document](https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/Project/Charter.md)</p>\n",
    "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"./assets/checkbox.png\">[Identify Data Sources](https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/Data_Report/Data%20Defintion.md)</p>\n",
    "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"./assets/checkbox.png\">[Create a Data Dictionary](https://github.com/Azure/Azure-TDSP-ProjectTemplate/tree/master/Docs/Data_Dictionaries)</p>\n",
    "\n",
    "<p style=\"border-bottom: 1px solid lightgrey;\"></p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lab 1.0 - Define Objectives\n",
    "Instructions:\n",
    "1. Read the Business Case that follows.\n",
    "2. Open the Charter.md file from the */Azure-TDSP-ProjectTempate/Docs/Project* folder and edit it to contain as much information as time allows - at a minimum, answer the first five bullets. (Note, you can find [this document online here](https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/Project/Charter.md) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Business Case\n",
    "\n",
    "*The Orange Telecom company in France is one of the largest operators of mobile and internet services in Europe and Africa and a global leader in corporate telecommunication services. They have 256 million customers worldwide. They have significant coverage in France, Spain, Belgium, Poland, Romania, Slovakia Moldova, and a large presence Africa and the Middle East. Customer Churn is always an issue in any company. Orange would like to predict the propensity of customers to switch provider (churn), buy new products or services (appetency), or buy upgrades or add-ons proposed to them to make the sale more profitable (up-selling). For this effort, they think churn is the first thing they would like to focus on.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Lab verification\n",
    "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"./assets/checkbox.png\">Ensure you have the first five bullets documented.</p>\n",
    "\n",
    "<p style=\"border-bottom: 1px solid lightgrey;\"></p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lab 1.1 - Identify Data Sources\n",
    "Instructions:\n",
    "1. Using the business case, open the Charter.md file from the */Azure-TDSP-ProjectTempate/Docs/Project* folder and edit it to answer the first bullet under **Architecture**. (Note, you can find [this document online](https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/Project/Charter.md) )\n",
    "2. *Optional*: Develop a Data Movement strategy for these datasets, assuming large amounts of data from at least three locations. \n",
    "\n",
    "#### Lab verification\n",
    "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"./assets/checkbox.png\">Ensure you understand where this data would be found.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p style=\"border-bottom: 3px solid lightgrey;\"></p> \n",
    "\n",
    "<h2><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"./assets/check.png\">Phase Two - Data Acquisition and Understanding</h2>\n",
    "\n",
    "Read the [Documentation Reference here](https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/lifecycle-data)\n",
    "\n",
    "The Data Aquisition and Understanding phase of the TDSP you ingest or access data from various locations to answer the questions the organization has asked. In most cases, this data will be in multiple locations. Once the data is ingested into the system, you’ll need to examine it to see what it holds. All data needs cleaning, so after the inspection phase, you’ll replace missing values, add and change columns. You’ll cover more extensive Data Wrangling tasks in other labs.\n",
    "\n",
    "In this section, we’ll use a single file-based dataset to train our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Goals for Data Acquisition and Understanding**\n",
    "\n",
    "  - Produce a clean, high-quality data set whose relationship to the target variables is understood. Locate the data set in the appropriate analytics environment so you are ready to model.\n",
    "  - Develop a solution architecture of the data pipeline that refreshes and scores the data regularly.\n",
    "\n",
    "**How to do it**\n",
    "\n",
    "  - Ingest the data into the target analytic environment.\n",
    "  - Explore the data to determine if the data quality is adequate to answer the question.\n",
    "  - Set up a data pipeline to score new or regularly refreshed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><img style=\"float: right; margin: 0px 15px 15px 0px;\" src=\"./assets/aml-logo.png\"><b>Using Azure Machine Learning for Data Acquisition and Understanding:</b></p>\n",
    "\n",
    "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"./assets/checkbox.png\">[Load data into storage environments for analytics](https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/ingest-data)</p>\n",
    "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"./assets/checkbox.png\">[Explore data in the Team Data Science Process](https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/explore-data)</p>\n",
    "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"./assets/checkbox.png\">[Sample data in Azure blob containers, SQL Server, and Hive tables](https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/sample-data)</p>\n",
    "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"./assets/checkbox.png\">[Access datasets with Python using the Azure Machine Learning Python client library](https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/python-data-access)</p>\n",
    "\n",
    "<p style=\"border-bottom: 1px solid lightgrey;\"></p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lab 2.0 - Ingest data from a local source\n",
    "Instructions:\n",
    " 1. Use Python Code in the cell to load customer data from the file:\n",
    " `./data/CATelcoCustomerChurnTrainingSample.csv`\n",
    " \n",
    " #### Lab verification\n",
    "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"./assets/checkbox.png\">Ensure that you have 29 columns and 20,468 rows loaded</p>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There should be 20468 obervations of 29 variables:\n"
     ]
    }
   ],
   "source": [
    "#LAB2.0 - Read data and verify\n",
    "# Read customer data from a single file\n",
    "df = pd.read_csv('./data/CATelcoCustomerChurnTrainingSample.csv') \n",
    "\n",
    "# Ensure that you have 29 columns and 20,468 rows loaded\n",
    "print('There should be 20468 obervations of 29 variables:')\n",
    "# <TODO: REPLACE THIS COMMENT WITH PYTHON CODE>\n",
    "\n",
    "# Optional - Instead, read the data from source:\n",
    "# https://github.com/Azure/MachineLearningSamples-ChurnPrediction/blob/master/data/CATelcoCustomerChurnTrainingSample.csv \n",
    "#/LAB2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p style=\"border-bottom: 1px solid lightgrey;\"></p> \n",
    "\n",
    "### Lab 2.1 - Data Exploration and Understanding\n",
    "Instructions:\n",
    " 1. Using the dataframe you loaded using the pandas library, explore the data, focusing on the shape, types, and missing values in the data.\n",
    "\n",
    "#### Lab verification\n",
    "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"./assets/checkbox.png\">Ensure that you understand the data, it's layout, and know any missing values in the data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#LAB2.1 - Explore Data\n",
    "# Explore the df Dataframe, using at least a five-number statistical summary.\n",
    "# NOTE: Your exploration may be much different - experiment with graphics as well.\n",
    "\n",
    "# Show the size and shape of data:\n",
    "# <TODO: REPLACE THIS COMMENT WITH PYTHON CODE>\n",
    "\n",
    "# Show the first and last 10 rows\n",
    "# <TODO: REPLACE THIS COMMENT WITH PYTHON CODE>\n",
    "\n",
    "# Show the dataframe structure:\n",
    "# <TODO: REPLACE THIS COMMENT WITH PYTHON CODE>\n",
    "\n",
    "# Check for missing values:\n",
    "# <TODO: REPLACE THIS COMMENT WITH PYTHON CODE>\n",
    "\n",
    "# perform a simple statistical display:    \n",
    "# <TODO: REPLACE THIS COMMENT WITH PYTHON CODE>\n",
    "\n",
    "#/LAB2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"./assets/check.png\">Phase Three - Modeling</h2>\n",
    "\n",
    "In this phase, we'll create the experiment runs, perform feature engineering, and run experiments with various settings and parameters. After selecting the best performing run, we'll create a trained model and save it for operationalization in the next phase.\n",
    "\n",
    "Read the [Documentation Reference here](https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/lifecycle-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Goals for modeling**\n",
    "  - Determine the optimal data features for the machine-learning model.\n",
    "  - Create an informative machine-learning model that predicts the target most accurately.\n",
    "  - Create a machine-learning model that's suitable for production.\n",
    "\n",
    "**How to do it**\n",
    "  - Feature engineering: Create data features from the raw data to facilitate model training.\n",
    "  - Model training: Find the model that answers the question most accurately by comparing their success metrics.\n",
    "  - Determine if your model is suitable for production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><img style=\"float: right; margin: 0px 15px 15px 0px;\" src=\"./assets/aml-logo.png\"><b>Using Azure Machine Learning for Modeling:</b></p>\n",
    "\n",
    "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"./assets/checkbox.png\">[Feature engineering in data science](https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/create-features)</p>\n",
    "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"./assets/checkbox.png\">[Feature selection](https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/select-features)</p>\n",
    "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"./assets/checkbox.png\">[Choose an algorithms for Microsoft Azure Machine Learning](https://docs.microsoft.com/en-us/azure/machine-learning/studio/algorithm-choice?toc=%2Fen-us%2Fazure%2Fmachine-learning%2Fteam-data-science-process%2Ftoc.json&bc=%2Fen-us%2Fazure%2Fbread%2Ftoc.json)</p>\n",
    "\n",
    "<p style=\"border-bottom: 1px solid lightgrey;\"></p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lab 3.0 - Experiement and Select a Model\n",
    "Instructions:\n",
    "\n",
    "1. Using Scikit-Learn in Python, implement the GaussianNB() and DecisionTreeClassifier() functions in an experiment over your dataframe. \n",
    " \n",
    "     a. For the Naive Bayes model, use a random seed of 42, and a .3 split.\n",
    " \n",
    " b. For the Decision Tree model, use a split of 20 and a random state of 99\n",
    "\n",
    "#### Lab verification</p>\n",
    "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"./assets/checkbox.png\">Find the accuracy of each algorithm</p>\n",
    "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"./assets/checkbox.png\">Which performed best? Can you improve it?</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#LAB3.0 - Customer Churn Prediction Experiment\n",
    "# For completeness of this example, let's re-import our libraries\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# We'll re-load the data as \"CustomerDataFrame\"\n",
    "CustomerDataFrame = pd.read_csv('data/CATelcoCustomerChurnTrainingSample.csv')\n",
    "\n",
    "# Fill all NA values with 0:\n",
    "# <TODO: REPLACE THIS COMMENT WITH PYTHON CODE>\n",
    "\n",
    "# Drop all duplicate observations:\n",
    "# <TODO: REPLACE THIS COMMENT WITH PYTHON CODE>\n",
    "\n",
    "# We don't need the 'year\" or 'month' variables\n",
    "# <TODO: REPLACE THIS COMMENT WITH PYTHON CODE>\n",
    "\n",
    "# Implement One-Hot Encoding for this model (https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/) \n",
    "columns_to_encode = list(CustomerDataFrame.select_dtypes(include=['category','object']))\n",
    "dummies = pd.get_dummies(CustomerDataFrame[columns_to_encode]) #\n",
    "\n",
    "# Drop the original categorical columns:\n",
    "CustomerDataFrame = CustomerDataFrame.drop(columns_to_encode, axis=1) # \n",
    "\n",
    "# Re-join the dummies frame to the original data:\n",
    "CustomerDataFrame = CustomerDataFrame.join(dummies)\n",
    "\n",
    "# Show the new columns in the joined dataframe:\n",
    "# <TODO: REPLACE THIS COMMENT WITH PYTHON CODE>\n",
    "\n",
    "# Experiment using Naive Bayes:\n",
    "nb_model = GaussianNB()\n",
    "# <TODO: REPLACE THIS COMMENT WITH PYTHON CODE>\n",
    "# <TODO: REPLACE THIS COMMENT WITH PYTHON CODE>\n",
    "\n",
    "train, test = train_test_split(CustomerDataFrame, random_state = random_seed, test_size = split_ratio)\n",
    "\n",
    "target = train['churn'].values\n",
    "train = train.drop('churn', 1)\n",
    "train = train.values\n",
    "nb_model.fit(train, target)\n",
    "\n",
    "expected = test['churn'].values\n",
    "test = test.drop('churn', 1)\n",
    "predicted = nb_model.predict(test)\n",
    "\n",
    "# Print out the Naive Bayes Classification Accuracy:\n",
    "# <TODO: REPLACE THIS COMMENT WITH PYTHON CODE>\n",
    "\n",
    "# Experiment using Decision Trees:\n",
    "dt_model = DecisionTreeClassifier(min_samples_split=20, random_state=99)\n",
    "dt_model.fit(train, target)\n",
    "# <TODO: REPLACE THIS COMMENT WITH PYTHON CODE>\n",
    "\n",
    "# Print out the Decision Tree Accuracy:\n",
    "print(\"Decision Tree Classification Accuracy\", accuracy_score(expected, predicted))\n",
    "\n",
    "#/LAB3.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"./assets/check.png\">Phase Four - Deployment</h2>\n",
    "\n",
    "In this phase we'll take the trained model and any other necessary assets and deploy them to a system that will respond to API requests.\n",
    "\n",
    "Read the [Documentation Reference here](https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/lifecycle-deployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Goal for Deployment**\n",
    " - Deploy models with a data pipeline to a production or production-like environment for final user acceptance\n",
    "\n",
    "**How to do it**\n",
    "  - Deploy the model and pipeline to a production or production-like environment for application consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><img style=\"float: right; margin: 0px 15px 15px 0px;\" src=\"./assets/aml-logo.png\"><b>Using Azure Machine Learning for Deployment:</b></p>\n",
    "\n",
    "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"./assets/checkbox.png\">[Deploy models in production](https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/deploy-models-in-production)</p>\n",
    "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"./assets/checkbox.png\">[Configure your environment to operationalize](https://docs.microsoft.com/en-us/azure/machine-learning/preview/cli-for-azure-machine-learning#o16n)</p>\n",
    "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"./assets/checkbox.png\">[Model management](https://docs.microsoft.com/en-us/azure/machine-learning/preview/deployment-setup-configuration)</p>\n",
    "\n",
    "<p style=\"border-bottom: 1px solid lightgrey;\"></p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lab 4.0 - Operationalize\n",
    "Instructions:\n",
    "1. Deploy the model and pipeline to a production or production-like environment for application consumption to one or more targets:\n",
    "  - Online websites\n",
    "  - Spreadsheets\n",
    "  - Dashboards\n",
    "  - Line-of-business applications\n",
    "  - Back-end applications\n",
    "\n",
    "#### Lab verification\n",
    "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"./assets/checkbox.png\">Save on disk a serialized model in Python (Pickle File) and create code that shows the artifacts (schema definition) needed to call it.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#LAB4.0a - Create the Model File\n",
    "# serialize the best performing model on disk:\n",
    "print (\"Serialize the model to a model.pkl file in the root\")\n",
    "# <TODO: REPLACE THIS COMMENT WITH PYTHON CODE>\n",
    "\n",
    "#/LAB4.0a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#LAB4.0b - Operationalization: Scoring the calls to the model\n",
    "# Prepare the web service definition before deploying\n",
    "# Import for the pickle\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# load the model file\n",
    "global model\n",
    "model = joblib.load('model.pkl')\n",
    "\n",
    "# Import for handling the JSON file\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Set up a sample \"call\" from a client:\n",
    "input_df = \"{\\\"callfailurerate\\\": 0, \\\"education\\\": \\\"Bachelor or equivalent\\\", \\\"usesinternetservice\\\": \\\"No\\\", \\\"gender\\\": \\\"Male\\\", \\\"unpaidbalance\\\": 19, \\\"occupation\\\": \\\"Technology Related Job\\\", \\\"year\\\": 2015, \\\"numberofcomplaints\\\": 0, \\\"avgcallduration\\\": 663, \\\"usesvoiceservice\\\": \\\"No\\\", \\\"annualincome\\\": 168147, \\\"totalminsusedinlastmonth\\\": 15, \\\"homeowner\\\": \\\"Yes\\\", \\\"age\\\": 12, \\\"maritalstatus\\\": \\\"Single\\\", \\\"month\\\": 1, \\\"calldroprate\\\": 0.06, \\\"percentagecalloutsidenetwork\\\": 0.82, \\\"penaltytoswitch\\\": 371, \\\"monthlybilledamount\\\": 71, \\\"churn\\\": 0, \\\"numdayscontractequipmentplanexpiring\\\": 96, \\\"totalcallduration\\\": 5971, \\\"callingnum\\\": 4251078442, \\\"state\\\": \\\"WA\\\", \\\"customerid\\\": 1, \\\"customersuspended\\\": \\\"Yes\\\", \\\"numberofmonthunpaid\\\": 7, \\\"noadditionallines\\\": \\\"\\\\\\\\N\\\"}\"\n",
    "\n",
    "# Cleanup \n",
    "input_df_encoded = json.loads(input_df)\n",
    "input_df_encoded = pd.DataFrame([input_df_encoded], columns=input_df_encoded.keys())\n",
    "input_df_encoded = input_df_encoded.drop('year', 1)\n",
    "input_df_encoded = input_df_encoded.drop('month', 1)\n",
    "input_df_encoded = input_df_encoded.drop('churn', 1)\n",
    "\n",
    "# Pre-process scoring data consistent with training data\n",
    "columns_to_encode = ['customersuspended', 'education', 'gender', 'homeowner', 'maritalstatus', 'noadditionallines', 'occupation', 'state', 'usesinternetservice', 'usesvoiceservice']\n",
    "dummies = pd.get_dummies(input_df_encoded[columns_to_encode])\n",
    "input_df_encoded = input_df_encoded.join(dummies)\n",
    "input_df_encoded = input_df_encoded.drop(columns_to_encode, axis=1)\n",
    "\n",
    "columns_encoded = ['age', 'annualincome', 'calldroprate', 'callfailurerate', 'callingnum',\n",
    "       'customerid', 'monthlybilledamount', 'numberofcomplaints',\n",
    "       'numberofmonthunpaid', 'numdayscontractequipmentplanexpiring',\n",
    "       'penaltytoswitch', 'totalminsusedinlastmonth', 'unpaidbalance',\n",
    "       'percentagecalloutsidenetwork', 'totalcallduration', 'avgcallduration',\n",
    "       'customersuspended_No', 'customersuspended_Yes',\n",
    "       'education_Bachelor or equivalent', 'education_High School or below',\n",
    "       'education_Master or equivalent', 'education_PhD or equivalent',\n",
    "       'gender_Female', 'gender_Male', 'homeowner_No', 'homeowner_Yes',\n",
    "       'maritalstatus_Married', 'maritalstatus_Single', 'noadditionallines_\\\\N',\n",
    "       'occupation_Non-technology Related Job', 'occupation_Others',\n",
    "       'occupation_Technology Related Job', 'state_AK', 'state_AL', 'state_AR',\n",
    "       'state_AZ', 'state_CA', 'state_CO', 'state_CT', 'state_DE', 'state_FL',\n",
    "       'state_GA', 'state_HI', 'state_IA', 'state_ID', 'state_IL', 'state_IN',\n",
    "       'state_KS', 'state_KY', 'state_LA', 'state_MA', 'state_MD', 'state_ME',\n",
    "       'state_MI', 'state_MN', 'state_MO', 'state_MS', 'state_MT', 'state_NC',\n",
    "       'state_ND', 'state_NE', 'state_NH', 'state_NJ', 'state_NM', 'state_NV',\n",
    "       'state_NY', 'state_OH', 'state_OK', 'state_OR', 'state_PA', 'state_RI',\n",
    "       'state_SC', 'state_SD', 'state_TN', 'state_TX', 'state_UT', 'state_VA',\n",
    "       'state_VT', 'state_WA', 'state_WI', 'state_WV', 'state_WY',\n",
    "       'usesinternetservice_No', 'usesinternetservice_Yes',\n",
    "       'usesvoiceservice_No', 'usesvoiceservice_Yes']\n",
    "\n",
    "# Now that they are encoded, some values will be \"empty\". Fill those with 0's:\n",
    "for column_encoded in columns_encoded:\n",
    "    if not column_encoded in input_df_encoded.columns:\n",
    "        input_df_encoded[column_encoded] = 0\n",
    "\n",
    "# Return final prediction\n",
    "pred = model.predict(input_df_encoded)\n",
    "\n",
    "# (In production you would replace Print() statement here with some sort of return to JSON)\n",
    "print('JSON sent to the prediction Model:', '\\n')\n",
    "print(input_df, '\\n')\n",
    "print('For the JSON string sent from the client, The prediction is returned as more JSON (0 = No churn, 1 = Churn):', '\\n')\n",
    "print(json.dumps(str(pred[0])))\n",
    "\n",
    "#/LAB4.0b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p style=\"border-bottom: 3px solid lightgrey;\"></p> \n",
    "\n",
    "<h2><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"./assets/check.png\">Phase Five - Customer Acceptance</h2>\n",
    "\n",
    "The final phase involves testing the model predictions on real-world queries to ensure that it meets all requirements. In this pase we also document the project so that all parameters are well-known. Finally, a mechanism is created to re-train the model. \n",
    "\n",
    "Read the [Documentation Reference here](https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/lifecycle-acceptance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Goals for Customer Acceptance**\n",
    " - Confirm that the pipeline, the model, and their deployment in a production environment satisfy the customer's objectives\n",
    " - Create a path for retraining your model\n",
    "\n",
    "**How to do it**\n",
    "  - System validation: Confirm that the deployed model and pipeline meet the customer's needs.\n",
    "  - Project hand-off: Hand the project off to the entity that's going to run the system in production\n",
    "  - Develop a \"ground truth\" mechanism and feed the new labels (if applicable) back into the retraining API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><img style=\"float: right; margin: 0px 15px 15px 0px;\" src=\"./assets/aml-logo.png\"><b>Using Azure Machine Learning for Customer Acceptance:</b></p>\n",
    "\n",
    "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"./assets/checkbox.png\">[Create an exit report of the project](https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/Project/Exit%20Report.md)</p>\n",
    "\n",
    "<p style=\"border-bottom: 1px solid lightgrey;\"></p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lab 5.0 - Testing and Handoff\n",
    "Instructions:\n",
    " 1. Review the [Create an exit report of the project](https://github.com/Azure/Azure-TDSP-ProjectTemplate/blob/master/Docs/Project/Exit%20Report.md) topic\n",
    "\n",
    "#### Lab verification\n",
    "<p><img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"./assets/checkbox.png\">Documentation reviewed and downloaded</p>\n",
    "\n",
    "<p style=\"border-bottom: 1px solid lightgrey;\"></p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p style=\"border-bottom: 3px solid lightgrey;\"></p> \n",
    "\n",
    "<h2>Workshop wrap-up</h2>\n",
    "\n",
    "This workshop introduced the Team Data Science Process, and walked you through each step of implementing it. Regardless of plaform or technology, you can use this process to guide your projects in Advanced Analytics from start to finish. \n",
    "\n",
    "You can learn more here: http://aka.ms/tdsp"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
